{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c09d602",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a469b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"For visi_depth\n",
    "\"\"\"\n",
    "# !CUDA_VISIBLE_DEVICES=3 python train.py --split eigen_zhou \\\n",
    "#                                             --load_weights_folder './history/model_22_09/models/weights_8' \\\n",
    "#                                             --png --backbone mobile_net_v3 \\\n",
    "#                                             --depth_decoder hr_depth \\\n",
    "#                                             --predict_visibility \\\n",
    "#                                             --model_name \"model_24_09\" \\\n",
    "#                                             --batch_size 6 \\\n",
    "#                                             --num_workers 4 \\\n",
    "#                                             --num_epochs 8 \\\n",
    "#                                             --log_frequency 3600 \\\n",
    "#                                             --start_saving_weight 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "973bde9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct  6 01:54:43 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    52W / 300W |  14822MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    56W / 300W |   3184MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    54W / 300W |   6329MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    55W / 300W |   4768MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b90825e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version trainer_v3\n",
      "Back bone:resnet - Depth decoder:hr_depth\n",
      "Use depth supervised loss\n",
      "loading model from folder history/the_last/models/weights_9\n",
      "Loading encoder weights...\n",
      "Loading depth weights...\n",
      "Loading pose_encoder weights...\n",
      "Loading pose weights...\n",
      "Loading Adam weights\n",
      "Training model named:\n",
      "   the_last\n",
      "Models and tensorboard events files are saved to:\n",
      "   history\n",
      "Training is using:\n",
      "   cuda\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "Using split:\n",
      "   eigen_zhou\n",
      "There are 39810 training items and 4424 validation items\n",
      "\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Training\n",
      "0it [00:00, ?it/s]/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n",
      "epoch  10 | batch      0 | examples/s:   1.0 | loss: 0.12365 | time elapsed: 00h00m13s | time left: 00h00m00s\n",
      "865it [09:33,  2.15it/s]^C\n",
      "865it [09:34,  1.50it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train-v2.py\", line 19, in <module>\n",
      "    trainer.train()\n",
      "  File \"/permanent_tuyendt23/T4E_ADAS/duonglh9/MDE/trainer_v3.py\", line 232, in train\n",
      "    self.run_epoch()\n",
      "  File \"/permanent_tuyendt23/T4E_ADAS/duonglh9/MDE/trainer_v3.py\", line 245, in run_epoch\n",
      "    for batch_idx, inputs in tqdm(enumerate(self.train_loader)):\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1142, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/queue.py\", line 179, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python train-v2.py --split eigen_zhou \\\n",
    "                                            --load_weights_folder \"history/the_last/models/weights_9\" \\\n",
    "                                            --start_epoch 10 \\\n",
    "                                            --png --backbone resnet \\\n",
    "                                            --depth_decoder hr_depth \\\n",
    "                                            --depth_supervised_loss \\\n",
    "                                            --supervised_loss_weight 0.1 \\\n",
    "                                            --model_name \"the_last\" \\\n",
    "                                            --batch_size 6 \\\n",
    "                                            --num_workers 6 \\\n",
    "                                            --num_epochs 10 \\\n",
    "                                            --start_saving_weight 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4c94f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version trainer_v3\n",
      "Back bone:mobile_net_v3 - Depth decoder:hr_depth\n",
      "Use depth supervised loss\n",
      "Training model named:\n",
      "   semi_sup_mobile\n",
      "Models and tensorboard events files are saved to:\n",
      "   history\n",
      "Training is using:\n",
      "   cuda\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "Using split:\n",
      "   eigen_zhou\n",
      "There are 19905 training items and 4424 validation items\n",
      "\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Training\n",
      "0it [00:00, ?it/s]/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n",
      "epoch   0 | batch      0 | examples/s:   1.5 | loss: 0.26742 | time elapsed: 00h00m13s | time left: 00h00m00s\n",
      "663it [16:58,  1.98s/it]epoch   0 | batch    663 | examples/s:   6.5 | loss: 0.17959 | time elapsed: 00h17m00s | time left: 16h43m43s\n",
      "1326it [33:26,  1.17it/s]epoch   0 | batch   1326 | examples/s:   7.8 | loss: 0.19021 | time elapsed: 00h33m27s | time left: 16h11m05s\n",
      "1531it [36:40,  1.46it/s]^C\n",
      "1531it [36:40,  1.44s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"train-v2.py\", line 19, in <module>\n",
      "    trainer.train()\n",
      "  File \"/permanent_tuyendt23/T4E_ADAS/duonglh9/MDE/trainer_v3.py\", line 232, in train\n",
      "    self.run_epoch()\n",
      "  File \"/permanent_tuyendt23/T4E_ADAS/duonglh9/MDE/trainer_v3.py\", line 258, in run_epoch\n",
      "    self.model_optimizer.step()\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 65, in wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/adam.py\", line 144, in step\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python train-v2.py --split eigen_zhou \\\n",
    "                                            --start_epoch 0 \\\n",
    "                                            --png --backbone mobile_net_v3 \\\n",
    "                                            --depth_decoder hr_depth \\\n",
    "                                            --depth_supervised_loss \\\n",
    "                                            --supervised_loss_weight 0.2 \\\n",
    "                                            --model_name \"semi_sup_mobile\" \\\n",
    "                                            --batch_size 6 \\\n",
    "                                            --num_workers 5 \\\n",
    "                                            --scheduler_step_size 5 \\\n",
    "                                            --num_epochs 12 \\\n",
    "                                            --start_saving_weight 1 \\\n",
    "                                            --make_it_quickly 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f55fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version trainer_v3\n",
      "Back bone:resnet - Depth decoder:hr_depth\n",
      "Training model named:\n",
      "   testing\n",
      "Models and tensorboard events files are saved to:\n",
      "   history\n",
      "Training is using:\n",
      "   cuda\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "Using split:\n",
      "   eigen_zhou\n",
      "There are 9952 training items and 4424 validation items\n",
      "\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Training\n",
      "0it [00:00, ?it/s]/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n",
      "epoch   0 | batch      0 | examples/s:   0.9 | loss: 0.15671 | time elapsed: 00h00m15s | time left: 00h00m00s\n",
      "331it [05:46,  1.17s/it]epoch   0 | batch    331 | examples/s:  13.7 | loss: 0.14127 | time elapsed: 00h05m48s | time left: 07h40m05s\n",
      "662it [11:32,  1.54it/s]epoch   0 | batch    662 | examples/s:  10.2 | loss: 0.14180 | time elapsed: 00h11m36s | time left: 07h33m39s\n",
      "993it [17:14,  1.14s/it]epoch   0 | batch    993 | examples/s:  12.8 | loss: 0.09576 | time elapsed: 00h17m16s | time left: 07h24m06s\n",
      "1324it [23:08,  1.45it/s]epoch   0 | batch   1324 | examples/s:  11.5 | loss: 0.11487 | time elapsed: 00h23m12s | time left: 07h21m43s\n",
      "1655it [28:57,  1.07it/s]epoch   0 | batch   1655 | examples/s:  13.7 | loss: 0.14339 | time elapsed: 00h28m59s | time left: 07h15m46s\n",
      "1658it [29:07,  1.05s/it]\n",
      "epoch   0 | validation | loss: 0.14526 \n",
      "Training\n",
      "0it [00:00, ?it/s]epoch   1 | batch      0 | examples/s:  11.0 | loss: 0.12524 | time elapsed: 00h29m29s | time left: 07h22m22s\n",
      "331it [05:37,  1.29s/it]epoch   1 | batch    331 | examples/s:  12.4 | loss: 0.11724 | time elapsed: 00h35m00s | time left: 07h11m52s\n",
      "662it [11:28,  1.29s/it]epoch   1 | batch    662 | examples/s:  12.8 | loss: 0.13185 | time elapsed: 00h40m51s | time left: 07h06m21s\n",
      "993it [17:07,  1.35it/s]epoch   1 | batch    993 | examples/s:  19.6 | loss: 0.10379 | time elapsed: 00h46m32s | time left: 06h59m09s\n",
      "1324it [22:36,  1.05s/it]epoch   1 | batch   1324 | examples/s:  15.6 | loss: 0.10750 | time elapsed: 00h51m59s | time left: 06h50m30s\n",
      "1655it [28:20,  1.76it/s]epoch   1 | batch   1655 | examples/s:  10.8 | loss: 0.12060 | time elapsed: 00h57m46s | time left: 06h44m47s\n",
      "1658it [28:31,  1.03s/it]\n",
      "epoch   1 | validation | loss: 0.10912 \n",
      "Training\n",
      "0it [00:00, ?it/s]epoch   2 | batch      0 | examples/s:   7.4 | loss: 0.10126 | time elapsed: 00h58m17s | time left: 06h48m02s\n",
      "331it [06:01,  1.18s/it]epoch   2 | batch    331 | examples/s:   9.5 | loss: 0.10829 | time elapsed: 01h04m12s | time left: 06h42m49s\n",
      "662it [12:11,  1.10it/s]epoch   2 | batch    662 | examples/s:   9.4 | loss: 0.10334 | time elapsed: 01h10m24s | time left: 06h39m09s\n",
      "993it [17:50,  1.03s/it]epoch   2 | batch    993 | examples/s:   9.1 | loss: 0.12587 | time elapsed: 01h16m01s | time left: 06h32m01s\n",
      "1324it [23:25,  1.47s/it]epoch   2 | batch   1324 | examples/s:   3.5 | loss: 0.08311 | time elapsed: 01h21m37s | time left: 06h25m03s\n",
      "1655it [29:13,  1.43it/s]epoch   2 | batch   1655 | examples/s:  13.0 | loss: 0.12066 | time elapsed: 01h27m24s | time left: 06h19m01s\n",
      "1658it [29:28,  1.07s/it]\n",
      "epoch   2 | validation | loss: 0.08625 \n",
      "Training\n",
      "0it [00:00, ?it/s]epoch   3 | batch      0 | examples/s:   9.6 | loss: 0.09160 | time elapsed: 01h28m41s | time left: 06h24m20s\n",
      "331it [07:26,  2.13it/s]epoch   3 | batch    331 | examples/s:   6.9 | loss: 0.11557 | time elapsed: 01h36m00s | time left: 06h24m03s\n",
      "438it [10:05,  1.45s/it]^C\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test sup weight\n",
    "\"\"\"\n",
    "!CUDA_VISIBLE_DEVICES=1 python train-v2.py --split eigen_zhou \\\n",
    "                                            --start_epoch 0 \\\n",
    "                                            --png --backbone resnet \\\n",
    "                                            --depth_decoder hr_depth \\\n",
    "                                            --model_name \"testing\" \\\n",
    "                                            --batch_size 6 \\\n",
    "                                            --num_workers 6 \\\n",
    "                                            --num_epochs 16 \\\n",
    "                                            --start_saving_weight 1 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ae95e",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750fc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from test_simple import test_simple\n",
    "from utils import *\n",
    "from kitti_utils import *\n",
    "from layers import *\n",
    "import datasets\n",
    "import networks\n",
    "from trainer_v2 import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c65c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2bf78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    def __init__(self):\n",
    "        # path\n",
    "        self.data_path = './kitti_data'\n",
    "        self.log_dir = './history/staff'\n",
    "        self.load_weights_folder = './history/mobile_hr/models/weights_15'\n",
    "        self.models_to_load = [\"encoder\", \"depth\", \"pose_encoder\", \"pose\"]\n",
    "        self.weights_init = True\n",
    "        \n",
    "        # training\n",
    "        self.depth_decoder = 'hr_depth'\n",
    "        self.backbone = 'mobile_net_v3'\n",
    "        self.model_name = ''\n",
    "        self.predict_visibility = True\n",
    "        self.split = 'eigen_zhou'\n",
    "        \n",
    "        self.num_layers = 18\n",
    "        self.dataset = 'kitti'\n",
    "        self.png = True\n",
    "        self.height = 192\n",
    "        self.width = 640\n",
    "        self.scales = [0,1,2,3]\n",
    "        self.frame_ids = [0,1]\n",
    "        self.min_depth = 0.1\n",
    "        self.max_depth = 100\n",
    "        self.disparity_smoothness = 1e-3\n",
    "        self.no_cuda = False\n",
    "        \n",
    "        # evaluation\n",
    "        self.eval_split = 'eigen'\n",
    "        self.splits_dir = './splits'\n",
    "        self.eval_show = True\n",
    "        \n",
    "        # optimization\n",
    "        self.batch_size = 2\n",
    "        self.num_workers = 1\n",
    "        self.learning_rate = 1e-4\n",
    "        self.num_epochs = 5\n",
    "        self.scheduler_step_size = 15\n",
    "\n",
    "        # ablation\n",
    "        self.avg_reprojection = False\n",
    "        self.disable_automasking = False\n",
    "        self.predictive_mask = False\n",
    "        self.no_ssim = False\n",
    "        self.pose_model_input = \"pairs\"\n",
    "        self.use_stereo = False\n",
    "        self.use_visibility = False\n",
    "        self.v1_multiscale = False\n",
    "        self.pose_model_type = \"separate_resnet\"\n",
    "opt = Opt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded14dc0",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c8c5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back bone:mobile_net_v3 - Depth decoder:hr_depth\n",
      "loading model from folder ./history/mobile_hr/models/weights_15\n",
      "Loading encoder weights...\n",
      "Loading depth weights...\n",
      "Loading pose_encoder weights...\n",
      "Loading pose weights...\n",
      "Training model named:\n",
      "   \n",
      "Models and tensorboard events files are saved to:\n",
      "   ./history/staff\n",
      "Training is using:\n",
      "   cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using split:\n",
      "   eigen_zhou\n",
      "There are 39810 training items and 4424 validation items\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_class = Trainer(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713f7059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 96, 320])\n",
      "torch.Size([2, 24, 48, 160])\n",
      "torch.Size([2, 40, 24, 80])\n",
      "torch.Size([2, 80, 12, 40])\n",
      "torch.Size([2, 160, 6, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "inputs = next(iter(train_class.train_loader))\n",
    "for key, ipt in inputs.items():\n",
    "    if type(ipt) is list:\n",
    "        continue\n",
    "    inputs[key] = ipt.to(train_class.device)\n",
    "features = train_class.models['encoder'](inputs['color_aug',0,0])\n",
    "for f in features:\n",
    "    print(f'{f.shape}')\n",
    "outputs, losses = train_class.process_batch(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c4111",
   "metadata": {},
   "source": [
    "## Something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "773c5ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 192, 640])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train_class.models['encoder'](inputs['color_aug',0,0])\n",
    "outputs = train_class.models['depth'](features)\n",
    "outputs[('disp',0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ecb3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class.models['visibility_net'] = train_class.models['visibility_net'].to(train_class.device)\n",
    "preds = train_class.models['visibility_net'](features)\n",
    "gts = torch.max(inputs['depth_gt'].view(inputs['depth_gt'].shape[0], inputs['depth_gt'].shape[1], -1), dim = 2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49be28f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 192, 640])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "min_depth = torch.Tensor([0.01, 0.01]).reshape(-1,1,1).to(train_class.device)\n",
    "disp_to_depth(outputs[('disp',0)], min_depth, max_depth)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b0dfad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 192, 640])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = preds.reshape(-1,1,1,1)\n",
    "(outputs[('disp',0)] / max_depth).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cceff15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6210.2197, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visibility_loss = nn.MSELoss()\n",
    "visibility_loss(preds, gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0105869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.97784222 0.30816645]\n",
      "   [0.01524218 0.91396792]]]\n",
      "\n",
      "\n",
      " [[[0.44496342 0.72753946]\n",
      "   [0.00526706 0.15152851]]]]\n",
      "(2, 1, 1, 1)\n",
      "[[[[0.48892111 0.15408322]\n",
      "   [0.00762109 0.45698396]]]\n",
      "\n",
      "\n",
      " [[[0.14832114 0.24251315]\n",
      "   [0.00175569 0.0505095 ]]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(2,1,2,2)\n",
    "print(a)\n",
    "b = np.array([2,3]).reshape(-1,1,1,1)\n",
    "print(b.shape)\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e74d7316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2873559 , 0.76961584])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

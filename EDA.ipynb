{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99666700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc47475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 28 00:56:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    63W / 300W |     11MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    68W / 300W |  11567MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    66W / 300W |  18729MiB / 32480MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    54W / 300W |  28106MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19480b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version trainer_v3\n",
      "Back bone:mobile_net_v3 - Depth decoder:hr_depth\n",
      "Use visibiity net\n",
      "loading model from folder ./history/model_26_09_lite/models_1/weights_2\n",
      "Loading encoder weights...\n",
      "Loading depth weights...\n",
      "Loading pose_encoder weights...\n",
      "Loading pose weights...\n",
      "Loading visibility_net weights...\n",
      "Loading Adam weights\n",
      "Training model named:\n",
      "   model_26_09_lite\n",
      "Models and tensorboard events files are saved to:\n",
      "   history\n",
      "Training is using:\n",
      "   cuda\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "Using split:\n",
      "   eigen_zhou\n",
      "There are 39810 training items and 4424 validation items\n",
      "\n",
      "/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "Training\n",
      "0it [00:00, ?it/s]/root/miniconda3/envs/mm-cuda11.1-torch1.9/lib/python3.7/site-packages/torch/nn/functional.py:4004: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n",
      "epoch   0 | batch      0 | examples/s:   1.1 | loss: 0.07782 | time elapsed: 00h00m13s | time left: 00h00m00s\n",
      "1327it [32:37,  1.78s/it]epoch   0 | batch   1327 | examples/s:   7.5 | loss: 0.07097 | time elapsed: 00h32m38s | time left: 26h39m45s\n",
      "2654it [1:09:59,  2.07s/it]epoch   0 | batch   2654 | examples/s:   9.0 | loss: 0.09857 | time elapsed: 01h10m01s | time left: 28h00m32s\n",
      "3981it [1:46:51,  1.24s/it]epoch   0 | batch   3981 | examples/s:   5.5 | loss: 0.07934 | time elapsed: 01h46m53s | time left: 27h54m34s\n",
      "5308it [2:22:30,  1.99s/it]epoch   0 | batch   5308 | examples/s:   6.8 | loss: 0.08894 | time elapsed: 02h22m32s | time left: 27h19m14s\n",
      "6635it [2:58:29,  1.61s/it]\n",
      "epoch   0 | validation | loss: 0.07478 \n",
      "Training\n",
      "0it [00:00, ?it/s]epoch   1 | batch      0 | examples/s:   6.9 | loss: 0.09000 | time elapsed: 02h58m49s | time left: 26h49m23s\n",
      "1327it [35:44,  1.58s/it]epoch   1 | batch   1327 | examples/s:   1.6 | loss: 0.07559 | time elapsed: 03h34m30s | time left: 26h13m06s\n",
      "2654it [1:08:55,  1.43s/it]epoch   1 | batch   2654 | examples/s:  12.3 | loss: 0.08324 | time elapsed: 04h07m39s | time left: 25h21m17s\n",
      "3981it [1:42:12,  1.98s/it]epoch   1 | batch   3981 | examples/s:   4.8 | loss: 0.07198 | time elapsed: 04h40m56s | time left: 24h34m57s\n",
      "5308it [2:16:08,  1.47s/it]epoch   1 | batch   5308 | examples/s:   6.1 | loss: 0.07620 | time elapsed: 05h14m52s | time left: 23h54m27s\n",
      "6635it [2:52:24,  1.56s/it]\n",
      "epoch   1 | validation | loss: 0.07360 \n",
      "Training\n",
      "0it [00:00, ?it/s]epoch   2 | batch      0 | examples/s:   5.2 | loss: 0.07811 | time elapsed: 05h51m26s | time left: 23h25m45s\n",
      "1327it [33:59,  1.30s/it]epoch   2 | batch   1327 | examples/s:  11.2 | loss: 0.07333 | time elapsed: 06h25m21s | time left: 22h46m15s\n",
      "2654it [1:08:36,  1.64s/it]epoch   2 | batch   2654 | examples/s:   9.8 | loss: 0.07406 | time elapsed: 06h59m56s | time left: 22h09m50s\n",
      "3226it [1:23:46,  1.43s/it]"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python train-v2.py --split eigen_zhou \\\n",
    "                                            --load_weights_folder './history/model_26_09_lite/models_1/weights_2' \\\n",
    "                                            --png --backbone mobile_net_v3 \\\n",
    "                                            --depth_decoder hr_depth \\\n",
    "                                            --predict_visibility \\\n",
    "                                            --model_name \"model_26_09_lite\" \\\n",
    "                                            --batch_size 6 \\\n",
    "                                            --num_workers 4 \\\n",
    "                                            --num_epochs 10 \\\n",
    "                                            --start_saving_weight 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b9727",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea5aefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_files.txt', 'val_files.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f'{SRC_FOLDER}/splits/eigen_zhou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2156ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: train: 39810 - val: 4424\n"
     ]
    }
   ],
   "source": [
    "# train / val in eigen_zhou split\n",
    "split_name = 'eigen_zhou'\n",
    "fname_train = []\n",
    "fname_val = []\n",
    "with open(f'{SRC_FOLDER}/splits/{split_name}/train_files.txt') as f:\n",
    "    fname_train = f.readlines()\n",
    "with open(f'{SRC_FOLDER}/splits/{split_name}/val_files.txt') as f:\n",
    "    fname_val = f.readlines()\n",
    "print(f'Number of images: train: {len(fname_train)} - val: {len(fname_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef11c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_files.txt',\n",
       " 'test_files_x3.txt',\n",
       " 'gt_depths_original.npz',\n",
       " '.ipynb_checkpoints',\n",
       " 'gt_depths.npz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f'{SRC_FOLDER}/splits/eigen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "037a5f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: train: 697\n"
     ]
    }
   ],
   "source": [
    "# test in eigen_zhou split\n",
    "split_name = 'eigen'\n",
    "fname_test = []\n",
    "with open(f'{SRC_FOLDER}/splits/{split_name}/test_files.txt') as f:\n",
    "    fname_test = f.readlines()\n",
    "print(f'Number of images: train: {len(fname_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f94630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

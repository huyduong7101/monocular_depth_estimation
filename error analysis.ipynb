{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d763c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from layers import disp_to_depth\n",
    "from utils import readlines\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './history'\n",
    "VERSION = 'model_24_09_lite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(dataset, index, show_gt = False, depth_pred = None):\n",
    "    item = dataset.__getitem__(index)\n",
    "    color_im = item[('color', 0, 0)].permute(1,2,0).cpu().detach().numpy() if type(item[('color', 0, 0)]) is torch.Tensor else item[('color', 0, 0)]\n",
    "    depth_map = item[\"depth_gt\"].permute(1,2,0).cpu().detach().numpy() if type(item[\"depth_gt\"]) is torch.Tensor else item[\"depth_gt\"]\n",
    "    \n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Input\")\n",
    "    plt.imshow(color_im)\n",
    "    \n",
    "    if show_gt:\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title(\"Ground truth\")\n",
    "        plt.imshow(depth_map)\n",
    "\n",
    "    if depth_pred is not None:\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.imshow(depth_pred.permute(1,2,0).cpu().detach().numpy() if type(depth_pred) is torch.Tensor else depth_pred)\n",
    "    \n",
    "    plt.show()  \n",
    "    \n",
    "def show_compare_result(img_color, depth_pred_1, depth_pred_2):\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Input\")\n",
    "    plt.imshow(img_color)\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Depth_pred_1\")\n",
    "    plt.imshow(depth_pred_1)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Depth_pred_2\")\n",
    "    plt.imshow(depth_pred_2)\n",
    "    \n",
    "    plt.show() \n",
    "    \n",
    "def change_color(new_pred_disp):\n",
    "    vmax = np.percentile(new_pred_disp, 95)\n",
    "    normalizer = mpl.colors.Normalize(vmin=new_pred_disp.min(), vmax=vmax)\n",
    "    mapper = cm.ScalarMappable(norm=normalizer, cmap='magma')\n",
    "    colormapped_im = (mapper.to_rgba(new_pred_disp)[:, :, :3] * 255).astype(np.uint8)\n",
    "    return colormapped_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Computation of error metrics between predicted and ground truth depths\n",
    "    \"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = (gt - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return [abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_pixel(gt_depth, pred_disp, opt):\n",
    "    gt_height, gt_width = gt_depth.shape[:2]\n",
    "    pred_disp = cv2.resize(pred_disp, (gt_width, gt_height))\n",
    "    pred_depth = 1 / pred_disp\n",
    "\n",
    "\n",
    "    if opt.eval_split == \"eigen\":\n",
    "        mask = np.logical_and(gt_depth > MIN_DEPTH, gt_depth < MAX_DEPTH)\n",
    "\n",
    "        crop = np.array([0.40810811 * gt_height, 0.99189189 * gt_height,\n",
    "                         0.03594771 * gt_width,  0.96405229 * gt_width]).astype(np.int32)\n",
    "        crop_mask = np.zeros(mask.shape)\n",
    "        crop_mask[crop[0]:crop[1], crop[2]:crop[3]] = 1\n",
    "        mask = np.logical_and(mask, crop_mask)\n",
    "    else:\n",
    "        mask = gt_depth > 0\n",
    "\n",
    "    pred_depth = pred_depth[mask]\n",
    "    gt_depth = gt_depth[mask]\n",
    "\n",
    "    pred_depth *= opt.pred_depth_scale_factor\n",
    "    if not opt.disable_median_scaling:\n",
    "        ratio = np.median(gt_depth) / np.median(pred_depth)\n",
    "#         ratios.append(ratio)\n",
    "        pred_depth *= ratio\n",
    "\n",
    "    pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
    "    pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
    "    \n",
    "    abs_rel = np.abs(pred_depth - gt_depth) / gt_depth\n",
    "    \n",
    "    return abs_rel, gt_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fac16",
   "metadata": {},
   "source": [
    "# Read opt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d905f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "LOG_DIR = './history'\n",
    "VERSION = 'semi_sup_28_09'        \n",
    "\n",
    "opt = json.load(open(f\"{LOG_DIR}/{VERSION}/models/opt.json\"))\n",
    "opt = Struct(**opt)\n",
    "print(opt.__dict__.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ebb0b",
   "metadata": {},
   "source": [
    "# Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4050334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_dir = \"./splits\"\n",
    "img_ext = '.png'\n",
    "test_filenames = readlines(os.path.join(splits_dir, opt.eval_split, \"test_files.txt\"))\n",
    "\n",
    "test_dataset = datasets.KITTIRAWDataset(opt.data_path, test_filenames,\n",
    "                                           192, 640,\n",
    "                                           [0], 4, is_train=False, img_ext=img_ext)\n",
    "\n",
    "fpath = os.path.join(\"./\", \"splits\", opt.split, \"{}_files.txt\")\n",
    "train_filenames = readlines(fpath.format(\"train\"))\n",
    "val_filenames = readlines(fpath.format(\"val\"))\n",
    "\n",
    "val_dataset = datasets.KITTIRAWDataset(opt.data_path, val_filenames, 192, 640, [0], 4, is_train=False, img_ext=img_ext)\n",
    "train_dataset = datasets.KITTIRAWDataset(opt.data_path, train_filenames, 192, 640, [0], 4, is_train=False, img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f970d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = []\n",
    "for i in range(len(train_filenames)//100):\n",
    "    max_depths.append(train_dataset.__getitem__(i)['depth_gt'].max())\n",
    "qlst = np.percentile(max_depths, [0,25,50,75,100])\n",
    "print(qlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    show_image(val_dataset, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbec657",
   "metadata": {},
   "source": [
    "# Read training_process.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(score_line):\n",
    "    score_dict = {}\n",
    "    for idx, line in enumerate(score_line):\n",
    "        string_scores = line.split(\"|\")\n",
    "        for string_score in string_scores:\n",
    "            if \"\\n\" in string_score:\n",
    "                continue\n",
    "            \n",
    "            name, value = string_score.strip().split() if \"Batch\" in string_score else string_score.split(\":\")[-2:]\n",
    "            if \"Loss sup_loss/0\" in name:\n",
    "                name = \"sup_loss/0\"\n",
    "            if(idx == 0):\n",
    "                score_dict[name.strip()] = [value.strip() if \"Epoch\" in value else float(value.strip())]\n",
    "            else:\n",
    "                score_dict[name.strip()].append(value.strip() if \"Epoch\" in value else float(value.strip()))\n",
    "    return score_dict\n",
    "\n",
    "def compare_score_plot(dic1, dic2, field):\n",
    "    print(field)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(dic1[field])\n",
    "    plt.title(\"Train\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(dic2[field])\n",
    "    plt.title(\"Valid\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d78269",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './history'\n",
    "VERSION = 'the_last'\n",
    "\n",
    "training_process_txt = []\n",
    "with open(f\"{LOG_DIR}/{VERSION}/training_process.txt\") as f:\n",
    "    training_process_txt = f.readlines()\n",
    "    \n",
    "valid_score_line = []\n",
    "train_score_line = []\n",
    "for line in training_process_txt:\n",
    "    if \"Validation\" in line:\n",
    "        valid_score_line.append(line)\n",
    "    else:\n",
    "        train_score_line.append(line)\n",
    "\n",
    "train_score_dict = create_dict(train_score_line)\n",
    "valid_score_dict = create_dict(valid_score_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_score_pd = pd.DataFrame(valid_score_dict)\n",
    "train_score_pd = pd.DataFrame(train_score_dict)\n",
    "train_score_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ef153",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_score_plot(train_score_pd, valid_score_pd, \"sup_loss/0\")\n",
    "compare_score_plot(train_score_pd, valid_score_pd, \"selsup_loss/0\")\n",
    "compare_score_plot(train_score_pd, valid_score_pd, \"loss\")\n",
    "compare_score_plot(train_score_pd, valid_score_pd, \"de/abs_rel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed378a87",
   "metadata": {},
   "source": [
    "# EA on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load predictions\n",
    "\"\"\"\n",
    "gt_path = os.path.join(\"./splits\", opt.eval_split, \"gt_depths.npz\")\n",
    "gt_depths = np.load(gt_path, allow_pickle=True, fix_imports=True, encoding='latin1')[\"data\"]\n",
    "\n",
    "old_model_path = \"./history/mobile_hr/models/weights_14\"\n",
    "new_model_path = \"./history/model_26_09_lite/models_1/weights_1\"\n",
    "old_pred_disps = np.load(f'{old_model_path}/disps_eigen_split.npy', allow_pickle=True, fix_imports=True, encoding='latin1')\n",
    "new_pred_disps = np.load(f'{new_model_path}/disps_eigen_split.npy', allow_pickle=True, fix_imports=True, encoding='latin1')\n",
    "max_depth_pred  = np.load(f'{new_model_path}/max_depth_eigen_split.npy', allow_pickle=True, fix_imports=True, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e00311",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_gt = np.array([x.max() for x in gt_depths])\n",
    "percentile_values = np.percentile(max_depth_gt, [0,5,50,75,100])\n",
    "print(percentile_values)\n",
    "percentile_values = np.percentile(max_depth_pred, [0,5,50,75,100])\n",
    "print(percentile_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute metric \n",
    "\"\"\"\n",
    "MIN_DEPTH = 1e-3\n",
    "MAX_DEPTH = 80\n",
    "\n",
    "def compute_metric(gt_depths, pred_disps, opt):\n",
    "    errors = []\n",
    "    abs_rels = []\n",
    "    ratios = []\n",
    "    rs_gt_depths = []\n",
    "\n",
    "    for i in tqdm(range(pred_disps.shape[0])):\n",
    "\n",
    "        gt_depth = gt_depths[i]\n",
    "        gt_height, gt_width = gt_depth.shape[:2]\n",
    "\n",
    "        pred_disp = pred_disps[i]\n",
    "        pred_disp = cv2.resize(pred_disp, (gt_width, gt_height))\n",
    "        pred_depth = 1 / pred_disp\n",
    "        \n",
    "                                \n",
    "        if opt.eval_split == \"eigen\":\n",
    "            mask = np.logical_and(gt_depth > MIN_DEPTH, gt_depth < MAX_DEPTH)\n",
    "\n",
    "            crop = np.array([0.40810811 * gt_height, 0.99189189 * gt_height,\n",
    "                             0.03594771 * gt_width,  0.96405229 * gt_width]).astype(np.int32)\n",
    "            crop_mask = np.zeros(mask.shape)\n",
    "            crop_mask[crop[0]:crop[1], crop[2]:crop[3]] = 1\n",
    "            mask = np.logical_and(mask, crop_mask)\n",
    "        else:\n",
    "            mask = gt_depth > 0\n",
    "\n",
    "        pred_depth = pred_depth[mask]\n",
    "        gt_depth = gt_depth[mask]\n",
    "\n",
    "        pred_depth *= opt.pred_depth_scale_factor\n",
    "        if not opt.disable_median_scaling:\n",
    "            ratio = np.median(gt_depth) / np.median(pred_depth)\n",
    "            ratios.append(ratio)\n",
    "            pred_depth *= ratio\n",
    "\n",
    "        pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
    "        pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
    "\n",
    "#         if opt.eval_return_result:\n",
    "#             pred_depths.append(copy.deepcopy(pred_depth))\n",
    "#             rs_gt_depths.append(copy.deepcopy(gt_depth))\n",
    "\n",
    "        error = compute_errors(gt_depth, pred_depth)\n",
    "        abs_rels.append(error[0])\n",
    "        errors.append(error)\n",
    "\n",
    "    if not opt.disable_median_scaling:\n",
    "        ratios = np.array(ratios)\n",
    "        med = np.median(ratios)\n",
    "        print(\" Scaling ratios | med: {:0.3f} | std: {:0.3f}\".format(med, np.std(ratios / med)))\n",
    "    \n",
    "    mean_errors = np.array(errors).mean(0)\n",
    "#     if opt.predict_visibility:\n",
    "#         max_depth_mse = MSE(gt_max_depths, pred_max_depths)\n",
    "#     else:\n",
    "#         max_depth_mse = -1\n",
    "    mean_errors = mean_errors.tolist()\n",
    "#     mean_errors.append(max_depth_mse)\n",
    "    print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "    print((\"&{: 8.3f}  \" * 7).format(*mean_errors) + \"\\\\\\\\\")\n",
    "    print(\"\\n-> Done!\")\n",
    "    \n",
    "    return errors, abs_rels, ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900cdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_errors, old_abs_rels, old_ratios = compute_metric(gt_depths, old_pred_disps, opt)\n",
    "new_errors, new_abs_rels, new_ratios = compute_metric(gt_depths, new_pred_disps, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b922de",
   "metadata": {},
   "source": [
    "## Compare depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29ea96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Visualization\n",
    "\"\"\"\n",
    "\n",
    "rank_idx = np.argsort(np.array(old_abs_rels))\n",
    "for i in range(len(rank_idx)):\n",
    "    idx = rank_idx[i]\n",
    "    \n",
    "    if (old_abs_rels[idx] - new_abs_rels[idx]) < 0.03 or gt_depths[idx].max() > 79:\n",
    "        continue\n",
    "    \n",
    "    img_color = test_dataset.__getitem__(idx)[('color_aug', 0, 0)].unsqueeze(0)\n",
    "    img_color = F.interpolate(img_color, [375,1242], mode = 'bilinear', align_corners = False).squeeze(0)\n",
    "    img_color = img_color.permute(1,2,0).numpy()\n",
    "    \n",
    "#     if gt_depths[idx].max() > 65 or (old_abs_rels[idx] < new_abs_rels[idx]):\n",
    "#         continue\n",
    "    \n",
    "    print(f\"Max_depth: Ground truth {gt_depths[idx].max()} - Prediction {max_depth_pred[idx]}\")\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(f\"Input\")\n",
    "    plt.imshow(img_color)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Mobile-HR-Depth | Abs_rel: {:.4f}\".format(old_abs_rels[idx]))\n",
    "    plt.imshow(change_color(old_pred_disps[idx]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"VisiDepth | Abs_rel: {:.4f}\".format(new_abs_rels[idx]))\n",
    "    plt.imshow(change_color(new_pred_disps[idx]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4486a9",
   "metadata": {},
   "source": [
    "## Plot metric + bins of depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b488150",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "rank_idx = np.argsort(np.array(old_abs_rels))\n",
    "for i in range(len(rank_idx)):\n",
    "    idx = rank_idx[i]\n",
    "    \n",
    "    if (old_abs_rels[idx] - new_abs_rels[idx]) > 0.00:\n",
    "        idxs.append(idx)\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 16\n",
    "len_bin = 80 // num_bins\n",
    "\n",
    "new_abs_rel_bins_all = [[] for i in range(num_bins)]\n",
    "old_abs_rel_bins_all = [[] for i in range(num_bins)]\n",
    "gt_depth_1d_all = []\n",
    "\n",
    "for idx in idxs:\n",
    "    gt_depth = gt_depths[idx]\n",
    "    new_pred_disp = new_pred_disps[idx]\n",
    "    old_pred_disp = old_pred_disps[idx]\n",
    "\n",
    "    new_abs_rel, gt_depth_1d = evaluate_per_pixel(gt_depth, new_pred_disp, opt)\n",
    "    old_abs_rel, gt_depth_1d = evaluate_per_pixel(gt_depth, old_pred_disp, opt)\n",
    "\n",
    "    values = np.arange(0,80+len_bin, len_bin)\n",
    "#     new_abs_rel_bins = np.zeros((num_bins,))\n",
    "#     old_abs_rel_bins = np.zeros((num_bins,))\n",
    "\n",
    "    for i in range(len(values)-1):\n",
    "        mask = np.logical_and(gt_depth_1d > values[i], gt_depth_1d < values[i+1])\n",
    "        if mask.sum() > 0:\n",
    "            new_abs_rel_bins_all[i].append(np.mean(new_abs_rel[mask]))\n",
    "            old_abs_rel_bins_all[i].append(np.mean(old_abs_rel[mask]))\n",
    "    gt_depth_1d_all.append(gt_depth_1d)\n",
    "\n",
    "gt_depth_1d_all = np.concatenate(gt_depth_1d_all)\n",
    "new_abs_rel_bins = [np.mean(x) if len(x) > 0 else 0 for x in new_abs_rel_bins_all]\n",
    "old_abs_rel_bins = [np.mean(x) if len(x) > 0 else 0 for x in old_abs_rel_bins_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15007cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Visualize histogram + line\n",
    "\"\"\"\n",
    "old_name = \"Mobile-HR-Depth (abs_rel)\"\n",
    "new_name = \"VisiDepth (abs_rel)\"\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8,4))\n",
    "ax1.set_xlabel(\"depth (m)\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# for histogram\n",
    "ax1.hist(gt_depth_1d_all, bins = num_bins, range=[0,80], weights = np.ones(len(gt_depth_1d_all)) / len(gt_depth_1d_all), edgecolor='black', color=\"lightgrey\")\n",
    "# for rect in ax.patches:\n",
    "#     height = rect.get_height()\n",
    "#     ax1.annotate('{:.1f}%'.format(100*height), xy=(rect.get_x()+rect.get_width()/2, height), \n",
    "#                 xytext=(0, 5), textcoords='offset points', ha='center', va='bottom', fontsize=8)\n",
    "ax1.yaxis.tick_right()\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax1.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "ax1.set_ylabel(\"Percentage (%)\")\n",
    "\n",
    "# for line\n",
    "ax2.plot(values[:-1] + len_bin / 2, new_abs_rel_bins, label=new_name, marker='o')\n",
    "ax2.plot(values[:-1] + len_bin / 2, old_abs_rel_bins, label=old_name, marker='o')\n",
    "ax2.legend(loc = 'center right')\n",
    "ax2.yaxis.tick_left()\n",
    "ax2.yaxis.set_label_position(\"left\")\n",
    "ax2.set_ylabel(\"Abs_rel\")\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"./history/images/plot_histogram_0000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf33d80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
